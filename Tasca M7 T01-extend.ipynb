{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerias que necesitamos para empezar\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400514b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mostra  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0       1    13.20        1.78  2.14               11.2        100   \n",
      "1       1    13.16        2.36  2.67               18.6        101   \n",
      "2       1    14.37        1.95  2.50               16.8        113   \n",
      "3       1    13.24        2.59  2.87               21.0        118   \n",
      "4       1    14.20        1.76  2.45               15.2        112   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.65        2.76                  0.26             1.28   \n",
      "1           2.80        3.24                  0.30             2.81   \n",
      "2           3.85        3.49                  0.24             2.18   \n",
      "3           2.80        2.69                  0.39             1.82   \n",
      "4           3.27        3.39                  0.34             1.97   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             4.38  1.05                          3.40     1050  \n",
      "1             5.68  1.03                          3.17     1185  \n",
      "2             7.80  0.86                          3.45     1480  \n",
      "3             4.32  1.04                          2.93      735  \n",
      "4             6.75  1.05                          2.85     1450  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dades= pd.read_csv('wineData.txt')\n",
    "\n",
    "\n",
    "dades.columns=[ 'Mostra','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols', 'Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue', 'OD280/OD315 of diluted wines','Proline'] \n",
    "print(dades.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b49a2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# SELECCIÓN DE VARIABLES\n",
    "#########################\n",
    "#split dataset in features and target variable: you need to divide given columns into two types of variables dependent(or target variable) and independent variable(or feature variables).\n",
    "\n",
    "Var_independents = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium','Total phenols','Flavanoids']\n",
    "X = dades[Var_independents] # Features (característiques)\n",
    "y = dades.Mostra # Target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6569ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# TRAIN TEST\n",
    "################\n",
    "\n",
    "# Split dataset into training set and test set: To understand model performance, dividing the dataset into a training set and a test set is a good strategy.\n",
    "# Let's split the dataset by using function train_test_split(). You need to pass 3 parameters features, target, and test_set size.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36f95e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# CREAR EL MODELO DE ARBOL DE DECISIÓN\n",
    "########################################\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1f41399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# EVALUAR EL MODELO\n",
    "####################\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61a7405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# CREAR MODELO AJUSTANDO PARÁMETROS Y EVALUARLO\n",
    "################################################\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2aa9ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7592592592592593\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# CREAR MODELO KNN \n",
    "################################################\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# The final step is to make predictions on our test data. To do so, execute the following script:\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "acc =  classifier.score(X_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d84de58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "# REPETIMOS EL PROCESO PERO NORMALIZANDO LOS DATOS - Modelo KNN\n",
    "###################################################\n",
    "\n",
    "# - - > Normalizamos:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# - - > Creamos modelo de classificación (KNN):\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# - - > Predecimos:\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# - - > Evaluamos:\n",
    "acc =  classifier.score(X_test, y_test)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7b5852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# DE NUEVO CLASIFICAMOS CON DATOS NORMALIZADOS - Modelo Árbol de decisión\n",
    "###############################################\n",
    "\n",
    "# - - > Normalizamos:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# - - > Creamos modelo de classificación (Arbol de decisión):\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# - - > Entrenamos el modelo\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# - - >  Predecimos la respuesta para los datos de testeo\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# - - > Evaluamos:\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "#¿? Me da la misma acc?? Por que? - - - > < - - || NO LO ENTIENDO ||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "824132ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.98        22\n",
      "           2       0.91      0.83      0.87        24\n",
      "           3       0.64      0.88      0.74         8\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.85      0.89      0.86        54\n",
      "weighted avg       0.91      0.89      0.89        54\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################\n",
    "# EVALUAMOS DE NUEVO LOS MODELOS \n",
    "###############################################\n",
    "\n",
    "# Explicación: el parámetro acc (precisión == acuracy) nos proporciona información muy general de nuestro modelo, cuando nuestra precisión es del 0,9, lo que significa que el 90 % de las predicciones serán correctas, es que el 10 % de error se reparte igualitariamente? O todo el error se concentra en una sola clase? Para resolverlo podemos utilizar los siguientes métodos: \n",
    "\n",
    "# - - - >  classification_report, \n",
    "# - - - >  confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing Seaborn's to use the heatmap \n",
    "import seaborn as sns\n",
    "\n",
    "# Adding classes names for better interpretation\n",
    "classes_names = ['Mostra 1','Mostra 2','Mostra 3']\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                  columns=classes_names, index = classes_names)\n",
    "                  \n",
    "# Seaborn's heatmap to better visualize the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d');\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f46889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# ENTENDIENDO LA MATRIZ DE CONFUSIÓN \n",
    "#####################################\n",
    "\n",
    "# En 4 ocasiones una muestra 2 se ha clasificado erroneamente como muestra 3\n",
    "\n",
    "\n",
    "# PROS Y CONTRAS DEL MÉTODO KNN\n",
    "\n",
    "# In this section, we'll present some of the pros and cons of using the KNN algorithm.\n",
    "# Pros\n",
    "\n",
    "#     It is easy to implement\n",
    "#     It is a lazy learning algorithm and therefore doesn't require training on all data points (only using the K-Nearest neighbors to predict). This makes the KNN algorithm much faster than other algorithms that require training with the whole dataset such as Support Vector Machines, linear regression, etc.\n",
    "#     Since KNN requires no training before making predictions, new data can be added seamlessly\n",
    "#     There are only two parameters required to work with KNN, i.e. the value of K and the distance function\n",
    "\n",
    "# Cons\n",
    "\n",
    "#     The KNN algorithm doesn't work well with high dimensional data because with a large number of dimensions, the distance between points gets \"weird\", and the distance metrics we use don't hold up\n",
    "#     Finally, the KNN algorithm doesn't work well with categorical features since it is difficult to find the distance between dimensions with categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80d0e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo SVM: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# PRUEVO OTRO DE LOS MODELOS EXPLICADO EN LA UNIDAD\n",
    "#####################################################\n",
    "\n",
    "# 1) # Support Vector Machines # \n",
    "\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy del modelo SVM:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# PROS Y CONTRAS DEL MÉTODO SVM\n",
    "# Advantages: SVM Classifiers offer good accuracy and perform faster prediction compared to Naïve Bayes algorithm. They also use less memory because they use a subset of training points in the decision phase. SVM works well with a clear margin of separation and with high dimensional space.\n",
    "# Disadvantages: SVM is not suitable for large datasets because of its high training time and it also takes more time in training compared to Naïve Bayes. It works poorly with overlapping classes and is also sensitive to the type of kernel used.\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83417730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrica del modelo 0.991869918699187\n",
      "Metricas cross_validation [0.92       0.96       0.92       0.875      0.91666667]\n",
      "Media de cross_validation 0.9183333333333333\n",
      "Metrica en Test 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# FEM EL CROSS VALIDATION\n",
    "############################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    " \n",
    " \n",
    "kf = KFold(n_splits=5)\n",
    " \n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "score = clf.score(X_train,y_train)\n",
    " \n",
    "print(\"Metrica del modelo\", score)\n",
    " \n",
    "scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=\"accuracy\")\n",
    " \n",
    "print(\"Metricas cross_validation\", scores)\n",
    " \n",
    "print(\"Media de cross_validation\", scores.mean())\n",
    " \n",
    "preds = clf.predict(X_test)\n",
    " \n",
    "score_pred = metrics.accuracy_score(y_test, preds)\n",
    " \n",
    "print(\"Metrica en Test\", score_pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
